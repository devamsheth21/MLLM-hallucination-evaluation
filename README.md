# MLLM-hallucination-evaluation
This project aims to evaluate Multimodal-Large Language Models (MLLMs) like InstructBLIP and Open-Flamingo and identifies hallucination scenarios based on various augmentatios applied to input image-prompt pairs.

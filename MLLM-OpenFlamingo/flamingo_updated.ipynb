{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56829b48-6ef9-4ec2-ac01-5d74e4b06208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c169c4d637c44d3e911d49d5b5d612bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamingo model initialized with 1384781840 trainable parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['vision_encoder.class_embedding', 'vision_encoder.positional_embedding', 'vision_encoder.proj', 'vision_encoder.conv1.weight', 'vision_encoder.ln_pre.weight', 'vision_encoder.ln_pre.bias', 'vision_encoder.transformer.resblocks.0.ln_1.weight', 'vision_encoder.transformer.resblocks.0.ln_1.bias', 'vision_encoder.transformer.resblocks.0.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.0.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.0.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.0.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.0.ln_2.weight', 'vision_encoder.transformer.resblocks.0.ln_2.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_1.weight', 'vision_encoder.transformer.resblocks.1.ln_1.bias', 'vision_encoder.transformer.resblocks.1.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.1.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.1.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.1.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_2.weight', 'vision_encoder.transformer.resblocks.1.ln_2.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_1.weight', 'vision_encoder.transformer.resblocks.2.ln_1.bias', 'vision_encoder.transformer.resblocks.2.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.2.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.2.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.2.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_2.weight', 'vision_encoder.transformer.resblocks.2.ln_2.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_1.weight', 'vision_encoder.transformer.resblocks.3.ln_1.bias', 'vision_encoder.transformer.resblocks.3.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.3.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.3.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.3.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_2.weight', 'vision_encoder.transformer.resblocks.3.ln_2.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_1.weight', 'vision_encoder.transformer.resblocks.4.ln_1.bias', 'vision_encoder.transformer.resblocks.4.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.4.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.4.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.4.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_2.weight', 'vision_encoder.transformer.resblocks.4.ln_2.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_1.weight', 'vision_encoder.transformer.resblocks.5.ln_1.bias', 'vision_encoder.transformer.resblocks.5.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.5.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.5.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.5.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_2.weight', 'vision_encoder.transformer.resblocks.5.ln_2.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_1.weight', 'vision_encoder.transformer.resblocks.6.ln_1.bias', 'vision_encoder.transformer.resblocks.6.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.6.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.6.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.6.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_2.weight', 'vision_encoder.transformer.resblocks.6.ln_2.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_1.weight', 'vision_encoder.transformer.resblocks.7.ln_1.bias', 'vision_encoder.transformer.resblocks.7.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.7.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.7.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.7.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_2.weight', 'vision_encoder.transformer.resblocks.7.ln_2.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_1.weight', 'vision_encoder.transformer.resblocks.8.ln_1.bias', 'vision_encoder.transformer.resblocks.8.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.8.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.8.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.8.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_2.weight', 'vision_encoder.transformer.resblocks.8.ln_2.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_1.weight', 'vision_encoder.transformer.resblocks.9.ln_1.bias', 'vision_encoder.transformer.resblocks.9.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.9.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.9.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.9.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_2.weight', 'vision_encoder.transformer.resblocks.9.ln_2.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_1.weight', 'vision_encoder.transformer.resblocks.10.ln_1.bias', 'vision_encoder.transformer.resblocks.10.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.10.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.10.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.10.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_2.weight', 'vision_encoder.transformer.resblocks.10.ln_2.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_1.weight', 'vision_encoder.transformer.resblocks.11.ln_1.bias', 'vision_encoder.transformer.resblocks.11.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.11.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.11.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.11.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_2.weight', 'vision_encoder.transformer.resblocks.11.ln_2.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_1.weight', 'vision_encoder.transformer.resblocks.12.ln_1.bias', 'vision_encoder.transformer.resblocks.12.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.12.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.12.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.12.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_2.weight', 'vision_encoder.transformer.resblocks.12.ln_2.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_1.weight', 'vision_encoder.transformer.resblocks.13.ln_1.bias', 'vision_encoder.transformer.resblocks.13.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.13.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.13.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.13.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_2.weight', 'vision_encoder.transformer.resblocks.13.ln_2.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_1.weight', 'vision_encoder.transformer.resblocks.14.ln_1.bias', 'vision_encoder.transformer.resblocks.14.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.14.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.14.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.14.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_2.weight', 'vision_encoder.transformer.resblocks.14.ln_2.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_1.weight', 'vision_encoder.transformer.resblocks.15.ln_1.bias', 'vision_encoder.transformer.resblocks.15.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.15.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.15.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.15.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_2.weight', 'vision_encoder.transformer.resblocks.15.ln_2.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_1.weight', 'vision_encoder.transformer.resblocks.16.ln_1.bias', 'vision_encoder.transformer.resblocks.16.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.16.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.16.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.16.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_2.weight', 'vision_encoder.transformer.resblocks.16.ln_2.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_1.weight', 'vision_encoder.transformer.resblocks.17.ln_1.bias', 'vision_encoder.transformer.resblocks.17.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.17.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.17.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.17.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_2.weight', 'vision_encoder.transformer.resblocks.17.ln_2.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_1.weight', 'vision_encoder.transformer.resblocks.18.ln_1.bias', 'vision_encoder.transformer.resblocks.18.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.18.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.18.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.18.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_2.weight', 'vision_encoder.transformer.resblocks.18.ln_2.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_1.weight', 'vision_encoder.transformer.resblocks.19.ln_1.bias', 'vision_encoder.transformer.resblocks.19.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.19.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.19.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.19.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_2.weight', 'vision_encoder.transformer.resblocks.19.ln_2.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_1.weight', 'vision_encoder.transformer.resblocks.20.ln_1.bias', 'vision_encoder.transformer.resblocks.20.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.20.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.20.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.20.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_2.weight', 'vision_encoder.transformer.resblocks.20.ln_2.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_1.weight', 'vision_encoder.transformer.resblocks.21.ln_1.bias', 'vision_encoder.transformer.resblocks.21.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.21.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.21.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.21.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_2.weight', 'vision_encoder.transformer.resblocks.21.ln_2.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_1.weight', 'vision_encoder.transformer.resblocks.22.ln_1.bias', 'vision_encoder.transformer.resblocks.22.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.22.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.22.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.22.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_2.weight', 'vision_encoder.transformer.resblocks.22.ln_2.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_1.weight', 'vision_encoder.transformer.resblocks.23.ln_1.bias', 'vision_encoder.transformer.resblocks.23.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.23.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.23.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.23.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_2.weight', 'vision_encoder.transformer.resblocks.23.ln_2.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.bias', 'vision_encoder.ln_post.weight', 'vision_encoder.ln_post.bias', 'lang_encoder.transformer.blocks.0.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.norm_f.weight', 'lang_encoder.old_decoder_blocks.0.norm_1.weight', 'lang_encoder.old_decoder_blocks.0.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.0.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.0.norm_2.weight', 'lang_encoder.old_decoder_blocks.0.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.0.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.1.norm_1.weight', 'lang_encoder.old_decoder_blocks.1.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.1.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.1.norm_2.weight', 'lang_encoder.old_decoder_blocks.1.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.1.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.2.norm_1.weight', 'lang_encoder.old_decoder_blocks.2.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.2.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.2.norm_2.weight', 'lang_encoder.old_decoder_blocks.2.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.2.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.3.norm_1.weight', 'lang_encoder.old_decoder_blocks.3.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.3.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.3.norm_2.weight', 'lang_encoder.old_decoder_blocks.3.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.3.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.4.norm_1.weight', 'lang_encoder.old_decoder_blocks.4.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.4.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.4.norm_2.weight', 'lang_encoder.old_decoder_blocks.4.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.4.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.5.norm_1.weight', 'lang_encoder.old_decoder_blocks.5.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.5.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.5.norm_2.weight', 'lang_encoder.old_decoder_blocks.5.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.5.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.6.norm_1.weight', 'lang_encoder.old_decoder_blocks.6.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.6.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.6.norm_2.weight', 'lang_encoder.old_decoder_blocks.6.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.6.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.7.norm_1.weight', 'lang_encoder.old_decoder_blocks.7.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.7.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.7.norm_2.weight', 'lang_encoder.old_decoder_blocks.7.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.7.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.8.norm_1.weight', 'lang_encoder.old_decoder_blocks.8.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.8.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.8.norm_2.weight', 'lang_encoder.old_decoder_blocks.8.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.8.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.9.norm_1.weight', 'lang_encoder.old_decoder_blocks.9.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.9.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.9.norm_2.weight', 'lang_encoder.old_decoder_blocks.9.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.9.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.10.norm_1.weight', 'lang_encoder.old_decoder_blocks.10.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.10.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.10.norm_2.weight', 'lang_encoder.old_decoder_blocks.10.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.10.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.11.norm_1.weight', 'lang_encoder.old_decoder_blocks.11.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.11.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.11.norm_2.weight', 'lang_encoder.old_decoder_blocks.11.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.11.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.12.norm_1.weight', 'lang_encoder.old_decoder_blocks.12.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.12.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.12.norm_2.weight', 'lang_encoder.old_decoder_blocks.12.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.12.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.13.norm_1.weight', 'lang_encoder.old_decoder_blocks.13.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.13.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.13.norm_2.weight', 'lang_encoder.old_decoder_blocks.13.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.13.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.14.norm_1.weight', 'lang_encoder.old_decoder_blocks.14.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.14.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.14.norm_2.weight', 'lang_encoder.old_decoder_blocks.14.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.14.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.15.norm_1.weight', 'lang_encoder.old_decoder_blocks.15.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.15.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.15.norm_2.weight', 'lang_encoder.old_decoder_blocks.15.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.15.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.16.norm_1.weight', 'lang_encoder.old_decoder_blocks.16.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.16.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.16.norm_2.weight', 'lang_encoder.old_decoder_blocks.16.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.16.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.17.norm_1.weight', 'lang_encoder.old_decoder_blocks.17.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.17.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.17.norm_2.weight', 'lang_encoder.old_decoder_blocks.17.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.17.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.18.norm_1.weight', 'lang_encoder.old_decoder_blocks.18.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.18.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.18.norm_2.weight', 'lang_encoder.old_decoder_blocks.18.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.18.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.19.norm_1.weight', 'lang_encoder.old_decoder_blocks.19.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.19.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.19.norm_2.weight', 'lang_encoder.old_decoder_blocks.19.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.19.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.20.norm_1.weight', 'lang_encoder.old_decoder_blocks.20.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.20.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.20.norm_2.weight', 'lang_encoder.old_decoder_blocks.20.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.20.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.21.norm_1.weight', 'lang_encoder.old_decoder_blocks.21.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.21.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.21.norm_2.weight', 'lang_encoder.old_decoder_blocks.21.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.21.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.22.norm_1.weight', 'lang_encoder.old_decoder_blocks.22.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.22.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.22.norm_2.weight', 'lang_encoder.old_decoder_blocks.22.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.22.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.23.norm_1.weight', 'lang_encoder.old_decoder_blocks.23.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.23.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.23.norm_2.weight', 'lang_encoder.old_decoder_blocks.23.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.23.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.24.norm_1.weight', 'lang_encoder.old_decoder_blocks.24.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.24.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.24.norm_2.weight', 'lang_encoder.old_decoder_blocks.24.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.24.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.25.norm_1.weight', 'lang_encoder.old_decoder_blocks.25.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.25.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.25.norm_2.weight', 'lang_encoder.old_decoder_blocks.25.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.25.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.26.norm_1.weight', 'lang_encoder.old_decoder_blocks.26.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.26.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.26.norm_2.weight', 'lang_encoder.old_decoder_blocks.26.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.26.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.27.norm_1.weight', 'lang_encoder.old_decoder_blocks.27.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.27.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.27.norm_2.weight', 'lang_encoder.old_decoder_blocks.27.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.27.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.28.norm_1.weight', 'lang_encoder.old_decoder_blocks.28.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.28.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.28.norm_2.weight', 'lang_encoder.old_decoder_blocks.28.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.28.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.29.norm_1.weight', 'lang_encoder.old_decoder_blocks.29.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.29.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.29.norm_2.weight', 'lang_encoder.old_decoder_blocks.29.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.29.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.30.norm_1.weight', 'lang_encoder.old_decoder_blocks.30.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.30.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.30.norm_2.weight', 'lang_encoder.old_decoder_blocks.30.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.30.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.31.norm_1.weight', 'lang_encoder.old_decoder_blocks.31.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.31.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.31.norm_2.weight', 'lang_encoder.old_decoder_blocks.31.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.31.ffn.down_proj.weight', 'lang_encoder.gated_cross_attn_layers.3.attn_gate', 'lang_encoder.gated_cross_attn_layers.3.ff_gate', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.3.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.3.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.7.attn_gate', 'lang_encoder.gated_cross_attn_layers.7.ff_gate', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.7.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.7.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.11.attn_gate', 'lang_encoder.gated_cross_attn_layers.11.ff_gate', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.11.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.11.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.15.attn_gate', 'lang_encoder.gated_cross_attn_layers.15.ff_gate', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.15.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.15.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.19.attn_gate', 'lang_encoder.gated_cross_attn_layers.19.ff_gate', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.19.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.19.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.23.attn_gate', 'lang_encoder.gated_cross_attn_layers.23.ff_gate', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.23.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.23.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.27.attn_gate', 'lang_encoder.gated_cross_attn_layers.27.ff_gate', 'lang_encoder.gated_cross_attn_layers.27.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.27.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.27.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.31.attn_gate', 'lang_encoder.gated_cross_attn_layers.31.ff_gate', 'lang_encoder.gated_cross_attn_layers.31.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.31.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.31.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.3.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from open_flamingo import create_model_and_transforms\n",
    "\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path=\"ViT-L-14\",\n",
    "    clip_vision_encoder_pretrained=\"openai\",\n",
    "    lang_encoder_path=\"anas-awadalla/mpt-7b\",\n",
    "    tokenizer_path=\"anas-awadalla/mpt-7b\",\n",
    "    cross_attn_every_n_layers=4\n",
    ")\n",
    "\n",
    "# grab model checkpoint from huggingface hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-9B-vitl-mpt7b\", \"checkpoint.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7036c3b-8f4e-41cc-b3c4-72e4a43cf1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset with the `large_random_1k` subset\n",
    "dataset = load_dataset('poloclub/diffusiondb', '2m_first_1k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d724f88a-3a7b-4cc0-b0bf-5536f4c8f66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a renaissance portrait of dwayne johnson, art in the style of rembrandt!! intricate. ultra detailed, oil on canvas, wet - on - wet technique, pay attention to facial details, highly realistic, cinematic lightning, intricate textures, illusionistic detail, \n"
     ]
    }
   ],
   "source": [
    "my_1k_data = dataset['train']\n",
    "print(my_1k_data['prompt'][5])\n",
    "\n",
    "#my_1k_data['image'][5].convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce46b763-a226-4df4-aa78-006e1f210c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  <image> the subject of the portrait is dwayne johnson<|endofchunk|>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "Step 1: Load images\n",
    "\"\"\"\n",
    "query_image = my_1k_data['image'][0]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 2: Preprocessing images\n",
    "Details: For OpenFlamingo, we expect the image to be a torch tensor of shape \n",
    " batch_size x num_media x num_frames x channels x height x width. \n",
    " In this case batch_size = 1, num_media = 3, num_frames = 1,\n",
    " channels = 3, height = 224, width = 224.\n",
    "\"\"\"\n",
    "vision_x = [image_processor(query_image).unsqueeze(0)]\n",
    "vision_x = torch.cat(vision_x, dim=0)\n",
    "vision_x = vision_x.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "\"\"\"\n",
    "Step 3: Preprocessing text\n",
    "Details: In the text we expect an <image> special token to indicate where an image is.\n",
    " We also expect an <|endofchunk|> special token to indicate the end of the text \n",
    " portion associated with an image.\n",
    "\"\"\"\n",
    "tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "lang_x = tokenizer(\n",
    "    [\"<image> \" + convert_question_to_statement(question)],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 4: Generate text\n",
    "\"\"\"\n",
    "generated_text = model.generate(\n",
    "    vision_x=vision_x,\n",
    "    lang_x=lang_x[\"input_ids\"],\n",
    "    attention_mask=lang_x[\"attention_mask\"],\n",
    "    max_new_tokens=20,\n",
    "    num_beams=3,\n",
    ")\n",
    "\n",
    "print(\"Generated text: \", tokenizer.decode(generated_text[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dabc97-904b-4d9d-8c99-b01a5437707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  <image> The lighting effect in the painting is very realistic. The lighting effect in the painting is very realistic. The lighting effect in the painting is\n"
     ]
    }
   ],
   "source": [
    "## pipeline function \n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def generate_text_from_image_and_question(image, question):\n",
    "    # Step 1: Load images (Replace this with your own image loading code)\n",
    "    query_image = image\n",
    "\n",
    "    # Step 2: Preprocessing images\n",
    "    vision_x = [image_processor(query_image).unsqueeze(0)]\n",
    "    vision_x = torch.cat(vision_x, dim=0)\n",
    "    vision_x = vision_x.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "    # Step 3: Preprocessing text\n",
    "    tokenizer.padding_side = \"left\"  # For generation padding tokens should be on the left\n",
    "    lang_x = tokenizer(\n",
    "        [\"<image> \" + convert_question_to_statement(question)],\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Step 4: Generate text\n",
    "    generated_text = model.generate(\n",
    "        vision_x=vision_x,\n",
    "        lang_x=lang_x[\"input_ids\"],\n",
    "        attention_mask=lang_x[\"attention_mask\"],\n",
    "        max_new_tokens=20,\n",
    "        num_beams=3,\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(generated_text[0])\n",
    "\n",
    "# Example usage:\n",
    "#image_url = \"your_image_url_here\"\n",
    "#image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "image = my_1k_data['image'][0]\n",
    "question = \"Q. What is the lighting effect in the painting?\"\n",
    "\n",
    "result_text = generate_text_from_image_and_question(image, question)\n",
    "print(\"Generated text: \", result_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
